## 1. sql语句执行顺序

* from
* on
* join
* where
* group by 
* 聚合函数
* having
* select
* distinct
* order by
* limit

由于mysql对sql做了扩展，因此group by 和having后也可使用select中的别名

## 2. 窗口函数

聚合函数：将每一组的多行记录聚合成一条

窗口函数：为每一组的多行记录都返回一条结果

* 聚合窗口函数
  * eg:sum(A)over(partition by B order by C rows n preceding)

    - rows n perceding：从当前行到前n行（一共n+1行）

    - rang/rows between 边界规则1 and 边界规则2：rang表示按照值的范围进行定义框架，rows表示按照行的范围进行定义框架


```mysql
rows between 2 preceding and 2 following #当前行往前2行+当前行+当前行往后2行（一共5行）
rows between 1 following 3 following #当前行的后1——>后3（共3行）
rows between unbounded preceding and current row #从第一行到当前行
```

* 排名窗口函数：格式，如rank()over(partition by A order by B )，假如值为10，20，20，30，40，则排名为：
  * rank：如果存在名次相同的数据，后续的排名将会产生跳跃。排名：12245
  * row_number：产生不重复递增的排名。排名：12345
  * dense_rank：即使存在名次相同的数据，后续的排名也是连续值。排名：12234
  * percent_rank：以百分比的形式返回当前行在分区中的名次。如果存在名次相同的数据，后续的排名将会产生跳跃

* 取值窗口函数

  * lag：可以返回窗口内当前行之前的第N行数据
  * lead：可以返回窗口内当前行之后的第N行数据

  ```mysq
  -- lag的用法
  select 
   dname,
   ename,
   hiredate,
   salary,
   lag(salary,1,'无') over(partition by dname order by hiredate) as last_1_time,
   lag(salary,2) over(partition by dname order by hiredate) as last_2_time 
  from employee;
  ```

  ![img](https://img-blog.csdnimg.cn/997c10c39c8a45f2a344e2c0175d0aad.png)

```
-- lead的用法
select 
 dname,
 ename,
 hiredate,
 salary,
 lead(hiredate,1,'2000-01-01') over(partition by dname order by hiredate) as last_1_time,
 lead(hiredate,2) over(partition by dname order by hiredate) as last_2_time 
from employee;
```

![img](https://img-blog.csdnimg.cn/0bb21376876147f984e42d31180feec1.png)

## 3. 其他函数

* 字符串切分：substring(str,position)/substring(str,position,length)
* 截取目标子串：substring_index(str,delim(分隔符),count)
* 时间差函数：
  * timestampdiff(unit,begin,end),用于返回计算两个日期指定单位的时间差(end-begin)
  * datediff(start,end) 返回start-end的天数差

* 格式化日期函数：date_format(date,format)

```mysql
substring用法
//str:www.baidu.com
select substring(str,5)
//result:baidu.com
select substring(str,5,3)
//result:bai
```



```mysql
//substring_index用法
//str:www.baidu.com
select substring_index(str,'.',-1);
//result:com
```



```mysql
//时间差函数用法：
select timestampdiff(month,'2018-01-01','2018-06-01') as result;
//result:5

//如果时间是YYYY-MM-DD HH:MM:SS格式，在计算天数差时，TIMESTAMPDIFF使用的是24小时制，即使是23:59:59，也不算做是一天，而DATEDIFF则是直接截取日期的部分相减。那么此时使用两个函数计算出来的天数是不一样的

-- 2
SELECT DATEDIFF('2022-04-30 00:00:00','2022-04-28 23:59:59');
-- 1
SELECT TIMESTAMPDIFF(DAY,'2022-04-28 23:59:59', '2022-04-30 00:00:00');
```

```mysql
//date_format
//date:2021-09-01 10:00:00	
select date_format(date,"%Y-%m-%d")
//result:2021-09-01

```



## 4. 执行一条 SQL 查询语句，期间发生了什么？

* 连接器： 身份认证和权限相关(登录 MySQL 的时候)。
* 查询缓存: 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。
  * 查询缓存有着一个致命的缺点，那就是查询缓存失效十分频繁。这里所说的查询缓存失效是指的只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此可能你废了很大的劲把结果存起来，还没使用呢，就被一个更新全清空了！这在高更新环境中会导致缓存命中率非常低

* 分析器: 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。
* 优化器： 按照 MySQL 认为最优的方案去执行。
* 执行器: 执行语句，然后从存储引擎返回数据。
  



## 5. 介绍下Innodb

InnoDB 是 MySQL 默认的存储引擎,是一个将表中的数据存储到磁盘上的存储引擎,支持事务，行级锁和外键

* Innodb的数据是按数据页（默认16KB)为单位进行读写的

* 为了高效查询数据所在的数据页，InnoDB采用b+树作为索引，每个节点都是一个数据页

  * 数据页内的记录按照主键顺序组成单项链表，为了加快在数据内的查询效率，设计了一个页目录，页目录里存储各个槽（每个槽相当于指针指向了不同组的最后一个记录），这样就可以通过二分法定位行记录在哪个槽，然后在遍历槽内的所有记录，找到对应的记录即可

  ![img](https://img-blog.csdnimg.cn/379f6d86d3d241b0a5decb409624abf0.png)

## 6. 介绍下索引

1. 索引的分类

* 按 [数据结构] 分类：B+树索引，Hash索引，Full-text索引
* 按 [物理存储] 分类：聚簇索引，非聚簇索引（二级索引、辅助索引）
  * 聚簇索引的**数据行的物理存储顺序与索引顺序一致**
  * 当表有主键时，主键就是聚簇索引；如果表没有定义主键，InnoDB 会选择一个唯一非空索引作为聚簇索引；如果也没有这样的索引，InnoDB 会生成一个隐藏的自增 ID 来充当聚簇索引。
  * 聚簇索引的B+树叶子节点存放的是实际数据（所有完整的用户记录）
  * 非聚簇索引里存储的是主键值

* 按 [字段特性] （用途）分类：主键索引，唯一索引，普通索引，前缀索引
* 按 [字段个数] 分类：单列索引，联合索引
* 特殊类型：覆盖索引（指查询所需的所有数据都能从索引中获取，不需要回表）

2. 什么时候使用索引

* 字段有唯一性限制的
* 经常用于where查询条件的字段
* 经常用于group by 和 order by 的字段
* 用于连接的字段

3. 索引优化

* 前缀索引优化：使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小。

* 覆盖索引优化：指的是在二级索引中就能查找到所需字段值，而不需要回到聚簇索引中查询，避免查询。比如我们要查询商品的名称和价格，那我们就建立一个联合索引[商品ID,名称,价格]，这样二级索引中存在所需数据，就不需要再次检索主键索引，从而避免回表。

* 使用自增主键：如果插入主键的值是随机的，那插入数据时，可能会插在数据页中间的某个位置，导致页分裂，自增主键保证了新记录总是在索引的最后面添加，这样可以避免频繁的页分裂和数据重组。

* 索引最好设置为not null

  * 第一原因：索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加难以优化，因为可为 NULL 的列会使索引、索引统计和值比较都更复杂，比如进行索引统计时，count 会省略值为NULL 的行。
  * 第二个原因：NULL 值是一个没意义的值，但是它会占用物理空间，所以会带来的存储空间的问题，因为 InnoDB 存储记录的时候，如果表中存在允许为 NULL 的字段，那么行格式中至少会用 1 字节空间存储 NULL 值列表，如下图的紫色部分

  ![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/row_format/COMPACT.drawio.png)

4. 索引失效

* 当我们使用左或者左右模糊匹配的时候，也就是 like %x 或者 like %x%这两种方式都会造成索引失效。而x%右模糊就不会失效，因为可以按照利用B+树有序的特点，去查找到x。而左模糊匹配，%林，如陈林，张林，王林，B+树不知道按照哪个索引值比较
* 对索引使用函数或表达式计算，eg:

```
select * from t_user where length(name)=6;
select * from t_user where id + 1 = 10;
```

* 联合索引不符合最左匹配原则
* 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效

## 7. 为什么Mysql采用B+树作为索引？

1. 什么是B+树？（B+树的特点？）

* 一个节点可以有多个子节点
* 非叶子节点存放索引，只有叶子节点存放数据
* 叶子节点之间用双向链表进行连接

2. 为什么Mysql采用B+树作为索引？

* B+树 vs 二叉树：随着数据量的增加，二叉树会越来越高，磁盘IO次数也会越来越多，而B+树在千万级别的数据量下，依旧能维持在3~4层，减少磁盘IO

* B+树 vs B树
  * **磁盘I/O和索引节点利用率**:B+树的非叶子节点不存储数据，只存储键值，这意味着B+树的非叶节点可以存更多的键，从而减少树的高度，降低磁盘I/O次数。
  * **范围查询**:B+树叶子节点维护了双向链表，因此能进行范围查询，而B树不能范围查询
  * **删除和插入性能**:B+树由于其叶子节点包含所有数据并且通过链表连接，使得其在进行插入和删除操作时更加高效，因为这些操作大多在叶子节点上完成，不需要频繁地修改内部节点
  * B树的优点：由于B树的每一个节点都包含key和value，因此我们根据key查找value时，只需要找到key所在的位置，就能找到value，但B+树只有叶子结点存储数据，索引每一次查找，都必须一次一次，一直找到树的最大深度处，也就是叶子结点的深度，才能找到value。也就是说B树最优复杂度为O(1)，而B+树固定为O(logn)
  
  B 树更适合键值对型的聚合数据库，比如 MongoDB，查询次数最优为 O(1)。虽然遍历数据的查询是相对常见的，但是 MongoDB 认为查询单个数据记录远比遍历数据更加常见，由于 B 树的非叶结点也可以存储数据，所以查询一条数据所需要的平均随机 IO 次数会比 B+ 树少，使用 B 树的 MongoDB 在类似场景中的查询速度就会比 MySQL 快

## 8. 介绍下事务？

1. 事务的四大特性？

* 原子性（Atomicity)：一个事务中的所有操作，要么全部成功，要么全部失败，不会结束在中间某个环节，一旦事务在执行过程中发生错误，就会回滚到事务发生前的状态
* 一致性（Consistency)：数据满足完整性约束
* 隔离性（Isolation)：多个事务并发执行时，一个事务的执行不会影响到其他事务的执行
* 持久性（Durability)：事务处理结束后，其对数据的修改就是永久的，即便系统故障也不会丢失

2. InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？

- 持久性是通过 redo log （重做日志）来保证的；
- 原子性是通过 undo log（回滚日志） 来保证的；

> undo log 主要分为两种：
>
> 1. insert undo log
>    代表事务在 insert 新记录时产生的 undo log, 只在事务回滚时需要，并且在事务提交后可以被立即丢弃
> 2. update undo log
>    事务在进行 update 或 delete 时产生的 undo log ; 不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被 purge 线程统一清除

- 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；
- 一致性则是通过原子性+隔离性来保证；

3. 并行事务会引发哪些问题？

* 脏读：一个事务读取到了另一个事务已修改但未提交的数据

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/9962f43d5d7fe5d5900c9cedcc12ab76.png)

* 不可重复读：在一个事务内多次读取同一个数据，出现了前后两次读到的数据不一样的情况

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/d816cc29ff055749768bcdbb47e5b54a.png)

* 幻读：在一个事务内多次查询某个符合查询条件的「记录数量」，出现前后两次查询到的记录数量不一样的情况

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/b642d6e28af1796ec9c56004e219709f.png)

4. 事务的隔离级别有哪些？

- 读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到；
- 读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到；
- 可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别；
- 串行化（serializable ）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；

![图片](https://img-blog.csdnimg.cn/img_convert/4e98ea2e60923b969790898565b4d643.png)

## 9. Mysql如何避免幻读？

`InnoDB`存储引擎在 RR 级别下通过 `MVCC`和 `Next-key Lock` 来解决幻读问题：

**1、执行普通 `select`，此时会以 `MVCC` 快照读的方式读取数据**

在快照读的情况下，RR 隔离级别只会在事务开启后的第一次查询生成 `Read View` ，并使用至事务提交。所以在生成 `Read View` 之后其它事务所做的更新、插入记录版本对当前事务并不可见，实现了可重复读和防止快照读下的 “幻读”

**2、执行 select...for update/lock in share mode、insert、update、delete 等当前读**

在当前读下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！`InnoDB` 使用 Next-key Lock来防止这种情况。当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。只要我不让你插入，就不会发生幻读

![img](https://img-blog.csdnimg.cn/20210717095320994.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzA1OTI5OQ==,size_16,color_FFFFFF,t_70)

![img](https://img-blog.csdnimg.cn/20210717095410649.png)

## MVCC原理

**一、原理概述**

1. 隐藏字段

`DB_TRX_ID（6字节）`：表示最后一次插入或更新该行的事务 id。此外，`delete` 操作在内部被视为更新，只不过会在记录头 `Record header` 中的 `deleted_flag` 字段将其标记为已删除

`DB_ROLL_PTR（7字节）` 回滚指针，指向该行的 `undo log` 。如果该行未被更新，则为空

`DB_ROW_ID（6字节）`：如果没有设置主键且该表没有唯一非空索引时，`InnoDB` 会使用该 id 来生成聚簇索引

![img](https://i-blog.csdnimg.cn/blog_migrate/a50549fa5fbc0f874ec9e053d82f8326.png)

2. undo log
3. Read View：主要是用来做可见性判断的, 即当我们某个事务执行快照读的时候，对该记录创建一个 `Read View` 读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的`undo log`里面的某个版本的数据。

>  数据可见性算法：在 `InnoDB` 存储引擎中，创建一个新事务后，执行每个 `select` 语句前，都会创建一个快照（Read View），**快照中保存了当前数据库系统中正处于活跃（没有 commit）的事务的 ID 号**。其实简单的说保存的是系统中当前不应该被本事务看到的其他事务 ID 列表（即 m_ids）。当用户在这个事务中要读取某个记录行的时候，`InnoDB` 会将该记录行的 `DB_TRX_ID` 与 `Read View` 中的一些变量及当前事务 ID 进行比较，判断是否满足可见性条件

原理概述：`MVCC` 的实现依赖于：**隐藏字段、Read View、undo log**。在内部实现中，`InnoDB` 通过数据行的 `DB_TRX_ID` 和 `Read View` 来判断数据的可见性，如不可见，则通过数据行的 `DB_ROLL_PTR` 找到 `undo log` 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 `Read View` 之前已经提交的修改和该事务本身做的修改。



**二、RC 和 RR 隔离级别下 MVCC 的差异**

在事务隔离级别 `RC` 和 `RR` （InnoDB 存储引擎的默认事务隔离级别）下，`InnoDB` 存储引擎使用 `MVCC`（非锁定一致性读），但它们生成 `Read View` 的时机却不同

- 在 RC 隔离级别下的 **`每次select`** 查询前都生成一个`Read View` (m_ids 列表)

> **在 RC 隔离级别下，事务在每次查询开始时都会生成并设置新的 Read View，所以导致不可重复读**

- 在 RR 隔离级别下只在事务开始后 **`第一次select`** 数据前生成一个`Read View`（m_ids 列表）



##  RedoLog 和BinLog	

* RedoLog：属于 InnoDB 存储引擎的一部分，是物理日志。它记录的是对数据页做了哪些修改，具体到每个数据页的字节级变化。Redo Log 主要用于崩溃恢复（crash recovery），确保即使数据库发生故障也能将内存中未刷盘的数据恢复到最后一次提交的状态

  * innoDB层面
  * 物理日志，记录该数据页更新的内容
  * 循环写，日志空间大小固定
  * 作用：crash-safe（崩溃恢复）

* BinLog：用于记录数据库执行的写入性操作(不包括查询)信息

  * Server层面
  * 逻辑日志，记录的是这个更新语句的原始逻辑（sql语句），以二进制的形式记录
  * 追加写，是指一份写到一定大小的时候会更换下一个文件，不会覆盖

  主从复制

  * 作用：主从复制、数据恢复(到特定的时间点)

* UndoLog：主要记录了数据的逻辑变化，比如一条INSERT语句，对应一条DELETE的undo log，对于每个UPDATE语句，对应一条相反的UPDATE的undo log，这样在发生错误时，就能回滚到事务之前的数据状态

为什么binlog不能崩溃恢复：Binlog 在事务提交后才记录，而 Redo Log 则在每个数据页修改时即刻记录，并同步到磁盘。因此，Redo Log 可以确保在崩溃时恢复提交的操作，而 Binlog 可能缺少这些实时变化

![image-20241109000431335](C:\Users\pc\AppData\Roaming\Typora\typora-user-images\image-20241109000431335.png)

## 11. MySQL 删除自增 id，随后重启 MySQL 服务，再插入数据，自增 id 会从几开始？

eg.比如一张 id 自增的表中有 8 条数据，删除两条后，重启 MySQL 服务后，又插入一条数据，那么此时自增的 id 会从几开始呢？

* 使用InnoDB引擎
  * mysql8.0以前，自增id会丢失（因为 InnoDB表把自增主键的最大ID记录到内存中），重启后会重新计算自增主键最大ID，因此是7
  * mysql8.0以后，自增id不会丢失（记录在redo 日志）中，因此是9
* 使用 myisam 引擎的情况下，不管 MySQL 版本为多少，自增的 id 都不会丢失。

## 12. char和varchar的区别

* 定长和变长：char表示定长，长度固定，如果插入数据的长度小于定义的长度则用空格填充；varchar表示变长，插入数据长度小于定义长度时，按实际长度存储
* 空间存储：char由于是定长，更消耗空间，varchar更节省空间
* 查找效率：char由于长度固定，存取速度要比varchar快
* 存储容量：char最多255个字符，varchar最多65532个字符

## 13. varchar 和 text的区别

text

* 变长
* 需要额外的字节存储长度
* 不能指定最大长度，适合存储大文本



##  删除表可以用什么

1. drop：删除表数据和表结构

2. truncate：删除表中所有数据，不删表结构

3. delete：删除表中所有或部分数据，不删表结构。（delete from...where...)

不同点：

* 删除的范围：drop（删除表中所有数据及表结构）>truncate（删除表中所有数据,本质上是先删表再建表）>=delete（删除表中所有数据或部分数据）
* 查询条件：delete可以使用查询条件进行表中数据删除，drop和truncate不可以
* 命令类型：delete属于DML，drop和truncate属于DDL
* 数据能否恢复：delete删除的数据可以恢复(事务回滚），但是drop和truncate删除的数据不能恢复
* 执行效率：drop>truncate>delete（delete是一条一条删除）
  

## SQL优化

* InnoDB引擎使用varchar代替char

* 某些字段可以用数值类型替代字符串类型

  * 节省空间
  * 避免计算时再从字符串转换从数值类型

* 避免索引失效的情况

  * 左模糊和左右模糊
  * or连接的两个字段，有一个不是索引列
  * 对索引使用函数或表达式计算
  * 使用联合索引但不符合最左匹配原则

* 索引不要建立在有大量重复数据，区分度低的字段上，如性别

* 尽量在where和order by常出现的字段使用索引，不要随便就建立索引

* 批量插入数据

  ```mysql
  //多次单条插入
  INSERT INTO student (id,NAME) VALUES(4,'name1');
  INSERT INTO student (id,NAME) VALUES(5,'name2');
  //一次插入多条：
  INSERT INTO student (id,NAME) VALUES(4,'name1'),(5,'name2');
  //避免每条语句都要开启事务和提交事务，而批量处理是一次事务开启和提交，自然速度飞升
  ```

* 一次性删除太多数据，可能造成锁表，会有lock wait timeout exceed的错误，所以建议分批操作

* update字段不加索引会锁表

* 尽量使用union all替代union（union在进行表链接后会筛选掉重复的记录，所以在表链接后会对所产生的结果集进行排序运算，删除重复的记录再返回结果。实际大部分应用中是不会产生重复的记录，最常见的是过程表与历史表UNION）

## 数据库三大范式

* 第一范式：属性不可再分，即表中的每个列都不可以再进行拆分

​	如表中字段有id,姓名,性别，这些字段一看就不能再分。而再比如现在有一个字段contact,将手机号码和住址放在了一起，而我们需要查询单独的手机号码或住址，此时就应该把contact字段再切分，才满足1NF

* 第二范式：在满足1NF的前提下，表中不存在部分依赖，非主键列要完全依赖于主键（主要是说在联合主键的情况下，非主键列不能只依赖于主键的一部分）比如联合主键为stu_id(学生id)和course_id(课程id)，那么score字段完全依赖于stu_id和course_id，而couse_name（课程名称）字段只依赖于couse_id，就不符合2NF

* 第三范式：满足第二范式；且不存在传递依赖，即非主属性不能与非主属性之间有依赖关系，非主属性必须直接依赖于主属性，不能间接依赖主属性。（A -> B, B ->C, A -> C）

  比如现在有字段：课程号，老师名称，老师电话，老师职位。那么很明显，老师电话和老师职位依赖于老师名称，并间接依赖于课程号，这就是传递依赖，不符合3NF

* BCNF：消除主属性对于不包含它的码的部分与传递函数依赖。如（A,B,C)为主属性，若A->B,B->A，则存在传递依赖，不符合BCNF。虽然，不满足BCNF，会导致一些冗余和一致性的问题。但是，将表分解成满足BCNF的表又可能丢失一些函数依赖。所以，一般情况下不会强制要求关系表要满足BCNF。



## 索引失效的场景

1. 对索引字段进行函数操作或计算

​	当在查询条件中对索引列进行函数操作（如 `UPPER(column)`）、计算（如 `column + 1`），或者使用类型转换（如 `CAST(column AS VARCHAR)`）时，索引无法被利用。

2. 模糊查询以通配符开头

​	在使用 `LIKE` 模糊查询时，如果以 `%` 开头（如 `LIKE '%value'`），则索引无法被使用，导致全表扫描。这是因为 `%` 在前面时，数据库无法通过索引定位记录，而只能逐行匹配。

3. 使用 `OR` 连接的条件

​	查询条件中包含 `OR` 语句时，如果某些字段没有建立索引，会导致索引失效并触发全表扫描。这在构建复杂查询条件时尤其常见。

4. 使用联合索引但不符合最左匹配原则

它要求查询条件必须从索引的最左列开始，按顺序逐列匹配，才能有效利用组合索引的加速效果。如联合索引如果是（A,B,C），此时只有(A),(A,B),(A,B,C)是有效的



## 为什么主键通常设置为自增

1. **提高插入效率**：自增主键按顺序递增，新的数据行总是追加到表的末尾，减少了中间插入带来的页分裂和重排，提升了插入性能。

2. **保持聚簇索引的顺序**：在 InnoDB 中，主键默认作为聚簇索引，自增主键可以确保数据按顺序存储，便于快速范围查询和排序。

3. **避免主键冲突**：在高并发环境下，自增主键由数据库自动生成，不需要人工管理，避免了重复和冲突的风险。

4. **便于管理和维护**：自增主键通常是整数型，占用空间小，查询效率高，也方便调试和定位数据。



## 联合索引在数据存储层面的实现

联合索引是按照定义时列的顺序逐层构建的。例如，创建一个 `(col1, col2, col3)` 的联合索引时，索引结构会按照 `col1` -> `col2` -> `col3` 的顺序排列。

在数据存储层面，这意味着 B+ 树会先根据 `col1` 的值进行排序和分组，再在相同 `col1` 值的范围内按 `col2` 排序，最后按 `col3` 排序。因此，每个索引键值实际上是 `(col1, col2, col3)` 的组合，这种组合决定了数据存储和查询的匹配方式





## mysql锁机制

按锁粒度从大到小分类：`表锁`，`页锁`和`行锁`；以及特殊场景下使用的`全局锁`

* 全局锁：全局锁就是对整个数据库实例加锁，加锁后整个实例就处于只读状态，后续的DML的写语句，DDL语句，已经更新操作的事务提交语句都将被阻塞。其典型的使用场景是做全库的逻辑备份，对所有的表进行锁定，从而获取一致性视图，保证数据的完整性。

```sql
flush tables with read lock ;
unlock tables ;
```

* 表级锁

  * 表锁：表锁的语法是lock tables … read/write。可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。如果在某个线程A中执行lock tables t1 read,t2 wirte;这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操作。连写t1都不允许

  * 元数据锁：meta data lock , 元数据锁，简写MDL。MDL加锁过程是系统自动控制，无需显式使用，在访问一张表的时候会自动加上。MDL锁主要作用是维护表元数据的数据一致性，**在表上有活动事务的时候，不可以对元数据进行写入操作。为了避免DML与DDL冲突**，保证读写的正确性。这里的元数据，大家可以简单理解为就是一张表的表结构。 也就是说，某一张表涉及到未提交的事务时，是不能够修改这张表的表结构的。

    ​	在MySQL5.5中引入了MDL，**当对一张表进行增删改查的时候，加MDL读锁(共享)；当对表结构进行变更操作的时候，加MDL写锁(排他)**。

    ​	常见的SQL操作时，所添加的元数据锁：

    ![img](https://i-blog.csdnimg.cn/blog_migrate/0a598bc533ef02be0b1246b3735aa58f.png)

  * 意向锁：意向锁的存在是为了协调行锁和表锁的关系，主要功能就是避免为了判断表是否存在行锁而去全表扫描。意向锁是自动加的。

    - 意向共享锁（IS锁）：事务在请求S锁前，要先获得IS锁

    - 意向排他锁（IX锁）：事务在请求X锁前，要先获得IX锁

    IS和IX之间是共享的，意向锁（共享和排他）和表级别的X锁是冲突的

* 行级锁：InnoDB存储引擎加锁默认是行锁，例如对某行数据添加共享锁、排它锁，都称为行锁。针对 唯一索引进行检索时，对已存在的记录进行等值匹配时，将会自动优化为行锁。不通过索引条件检索数据(InnoDB的行锁是针对于索引加的锁)，那么InnoDB将对表中的所有记录加锁，此时就会升级为表锁

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a4c912378581489592e0da8705a97e8e.png)

  > 简单的insert会在insert的行对应的索引记录上加一个排它锁，这是一个record lock，并没有gap，所以并不会阻塞其他session在gap间隙里插入记录。
  >
  > 不过在insert操作之前，还会加一种锁，官方文档称它为insertion intention gap lock，也就是意向的gap锁。这个意向gap锁的作用就是预示着当多事务并发插入相同的gap空隙时，只要插入的记录不是gap间隙中的相同位置，则无需等待其他session就可完成，这样就使得insert操作无须加真正的gap lock。
  > 假设有一个记录索引包含键值4和7，不同的事务分别插入5和6，每个事务都会产生一个加在4-7之间的插入意向锁，获取在插入行上的排它锁，但是不会被互相锁住，因为数据行并不冲突。
  >
  > 假设发生了一个唯一键冲突错误，那么将会在重复的索引记录上加读锁。当有多个session同时插入相同的行记录时，如果另外一个session已经获得该行的排它锁，那么将会导致死锁。
  >
  
  * 间隙锁（Gap Lock）：是 InnoDB 在 RR（可重复读）隔离级别下为了解决 **幻读问题** 时引入的锁机制。间隙锁是InnoDB 中行锁的一种。
  
    请务必牢记：**使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。**
  
    举例来说，假如 emp 表中只有 101 条记录，其 empid 的值分别是1, 2, …, 100, 101，下面的SQL：
  
  ```sql
  SELECT * FROM emp WHERE empid > 100 FOR UPDATE
  当我们用条件检索数据，并请求共享或排他锁时，InnoDB 不仅会对符合条件的 empid 值为 101 的记录加锁，也会对 empid 大于 101（这些记录并不存在）的 “间隙” 加锁。
  这个时候如果你插入 empid 等于 102 的数据的，如果那边事物还没有提交，那你就会处于等待状态，无法插入数据。
  ```
  
  *   临键锁（Next-Key Lock）：行锁和间隙锁的组合，同时锁住数据，并锁住数据前面的间隙 Gap，在 RR 隔离级别下支持。

> 间隙锁和临键锁的场景：
>
> 1. 索引上的等值查询 (唯一索引，例如主键索引)，给 **不存在的记录** 加锁时,优化为间隙锁。
> 2. 索引上的范围查询(唯一索引)–会访问到不满足条件的第一个值为止。
> 3. 索引上的等值查询(普通索引)，向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁。
> 4. 在SELECT ... FOR UPDATE 或 LOCK IN SHARE MODE 语句中，查询具有范围条件的行时，InnoDB 会加上临键锁来确保在当前事务执行过程中，其他事务无法在该范围内插入数据，防止幻读。



## 联合索引是什么？遵循什么原则

1. 定义：它是将多个列组合在一起形成的索引
2. 工作原理：联合索引会按照索引中定义的多个列依次排序，并根据排序结果建立索引树。例如，一个 `(A, B, C)` 的联合索引会首先按照 `A` 列排序，若 `A` 列的值相同，再按 `B` 列排序，最后按 `C` 列排序。这种方式可以加速多列查询的匹配过程。

3. 最左前缀匹配原则：联合索引按顺序排列并按顺序使用，因此联合索引只能用于查询中包含**最左连续字段 **的情况。例如 `(A, B, C)` 的联合索引可以用于 `(A)`、`(A, B)` 和 `(A, B, C)` 的查询，但不能用于 `(B, C)` 或仅 `(C)` 的查询。

```SQL
-- 假设存在联合索引 (A, B, C)
SELECT * FROM table WHERE A = 1;      -- 使用索引
SELECT * FROM table WHERE A = 1 AND B = 2;  -- 使用索引
SELECT * FROM table WHERE A = 1 AND B = 2 AND C = 3;  -- 使用索引
SELECT * FROM table WHERE B = 2;      -- 不使用索引
SELECT * FROM table WHERE C = 3;      -- 不使用索引

```



## 分库分表

[参考](https://blog.csdn.net/weixin_44062339/article/details/100491744)

1. 对于分库分表的理解，什么场景，具体怎么实现，选型的权衡，重点在于水平和垂直的区别
2. 为什么分表后查询效率提高了，要求逻辑闭环的解释

垂直分表：可以把一个宽表的字段按访问频次、是否是大字段的原则拆分为多个表，这样既能使业务清晰，还能提升部分性能。拆分后，尽量从业务角度避免联查，否则性能方面将得不偿失。

垂直分库：以把多个表按业务耦合松紧归类，分别存放在不同的库，这些库可以分布在不同服务器，从而使访问压力被多服务器负载，大大提升性能，同时能提高整体架构的业务清晰度，不同的业务库可根据自身情况定制优化方案。但是它需要解决跨库带来的所有复杂问题。

水平分库：可以把一个表的数据(按数据行)分到多个不同的库，每个库只有这个表的部分数据，这些库可以分布在不同服务器，从而使访问压力被多服务器负载，大大提升性能。它不仅需要解决跨库带来的所有复杂问题，还要解决数据路由的问题(数据路由问题后边介绍)。

水平分表：可以把一个表的数据(按数据行)分到多个同一个数据库的多张表中，每个表只有这个表的部分数据，这样做能小幅提升性能，它仅仅作为水平分库的一个补充优化。

> 为什么大字段IO效率低：第一是由于数据量本身大，需要更长的读取时间；第二是跨页，页是数据库存储单位，很多查找及定位操作都是以页为单位，单页内的数据行越多数据库整体性能越好，而大字段占用空间大，单页内存储行数少，因此IO效率较低。第三，数据库以行为单位将数据加载到内存中，这样表中字段长度较短且访问频率较高，内存能加载更多的数据，命中率更高，减少了磁盘IO，从而提升了数据库性能。
>



3. 主从分库一般怎么做数据同步



4. 主从分库里面会有一致性问题吗，分析分析这个场景满足CAP中的什么，要求举例子逻辑闭环的解释

**一致性**（Consistency）：在分布式系统中，所有节点看到的数据都是相同的，即系统的状态在任何时刻都是一致的。

**可用性**（Availability）：系统必须保证在任何时刻都能够处理请求并返回正确的结果，即系统一直处于可用状态。

**分区容错性**（Partition tolerance）：系统在遇到网络分区故障时仍然能够保持正常的工作，即系统能够容忍任意数量的消息丢失或网络分区。

主从分库的特性通常是 AP 系统（可用性和分区容错性优先），牺牲了一致性。

1. 可用性（Availability, A）
主从分库通过从库分担读请求，主库处理写请求，即使部分从库或主库宕机，其他节点仍可提供服务。
例子：
从库宕机时，读操作可以转到其他从库。
主库宕机时，可通过故障切换机制选举新的主库。
2. 分区容错性（Partition Tolerance, P）
主从分库允许主库与从库之间的通信中断（网络分区）。
在网络恢复后，从库会继续从主库同步数据，确保最终一致性。
例子：
网络分区时，主库仍能处理写请求，从库暂时无法同步，但系统整体不会停止。
3. 一致性（Consistency, C）
主从分库中，写入操作先更新主库，再异步同步到从库，这种异步机制无法保证强一致性。
在延迟窗口中，读操作可能获取到旧数据，数据一致性受到牺牲。



## explain命令

**一、EXPLAIN 命令简介**

EXPLAIN 命令用于获取 MySQL 查询的执行计划信息。它可以显示查询语句如何被 MySQL 解析和执行，包括使用了哪些索引、表的连接方式、查询的行数估计等。通过分析这些信息，我们可以找出查询性能瓶颈，并进行相应的优化。

使用方式：

```sql
在 MySQL 中，使用 EXPLAIN 命令非常简单。只需要在查询语句前加上“EXPLAIN”关键字即可。例如：
EXPLAIN SELECT * FROM table_name WHERE column_name = 'value';
执行上述语句后，MySQL 会返回一个包含查询执行计划信息的结果集。
```

**二、使用 EXPLAIN 命令的方法**

`id`：查询的标识符。如果有多个查询（如子查询或连接查询），每个查询都会有一个唯一的 id。
`select_type`：查询的类型，如 SIMPLE（简单查询）、PRIMARY（主查询）、SUBQUERY（子查询）等。
`table`：查询涉及的表名。
`partitions`：查询涉及的分区，如果表没有分区，则为 NULL。
`type`：连接类型，也就是访问表的方式，表示 MySQL 如何查找表中的行。常见的连接类型有 `ALL`（全表扫描）、`index`（索引全扫描）、`range`（索引范围扫描）、`ref`（使用非唯一索引的等值查询）、`eq_ref`：对唯一索引的引用，效率较高、`const`：查询是基于常量值进行的匹配,表示通过索引只能匹配到一行数据。连接类型的性能从好到坏依次为：const > eq_ref > ref > range > index > ALL。
`possible_keys`：可能使用的索引。
`key`：实际使用的索引。如果为 NULL，表示没有使用索引。
`key_len`：索引字段的长度。
`ref`：连接条件所引用的列或常量
`rows`：MySQL 估计需要扫描的行数。
`filtered`：表示查询结果经过表过滤后的预计百分比，它显示了查询条件对表数据的过滤效果。filtered = (满足表条件的记录数 / 该表的总记录数) * 100%。它的值越大，表示索引过滤性越好（表示索引直接命中，而不需要一条条过滤）；值越小，表示索引过滤性越差，甚至没有使用到索引。由此可见，filtered的100%确实是要比1%要好
`Extra`：额外的信息，如使用了临时表、文件排序等。

**三、实例解析**

假设我们有一个名为 `users` 的表，包含 `id`、`name`、`age`、`email` 等字段，并且在 `name` 字段上建立了索引。我们执行以下查询：

```sql
EXPLAIN SELECT * FROM users WHERE name = 'John';
```

假设返回的结果如下：

```sql
id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra
-- | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------
1 | SIMPLE | users | NULL | ref | name_idx | name_idx | 767 | const | 10 | 100.00 | NULL
```

在这个例子中，我们可以看出以下信息：

`id` 为 1，表示这是一个简单查询。
`type` 为 `ref`，表示使用了非唯一索引的等值查询，性能较好。
`key` 为 `name_idx`，表示实际使用了 name 字段上的索引。
`rows` 为 10，表示 MySQL 估计需要扫描 10 行数据。
`filtered` 为 100.00，表示查询结果没有进行过滤。

如果我们执行一个没有使用索引的查询，比如：

```sql
EXPLAIN SELECT * FROM users WHERE age = 30;
```

假设返回的结果如下：

```sql
id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra
-- | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------
1 | SIMPLE | users | NULL | ALL | NULL | NULL | NULL | NULL | 1000 | 10.00 | Using where

```

在这个例子中，我们可以看出：

- `type` 为 `ALL`，表示进行了全表扫描，性能较差。
- `key` 为 `NULL`，表示没有使用索引。
- `rows` 为 1000，表示 MySQL 估计需要扫描 1000 行数据。
- `Extra` 为 `Using where`，表示使用了 `WHERE` 子句进行过滤。

